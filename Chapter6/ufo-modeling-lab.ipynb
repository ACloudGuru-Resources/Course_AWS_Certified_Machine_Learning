{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UFO Sightings K-Means Clustering\n",
    "### Modeling Lab\n",
    "\n",
    "The goal of this notebook is to analyze where Mr. K should build his extraterrestrial life facilities using the K-Means algorithm. \n",
    "\n",
    "What we plan on accomplishing is the following:\n",
    "1. [Load dataset onto Notebook instance from S3](#Step-1:-Loading-the-data-from-Amazon-S3)\n",
    "2. [Cleaning, transforming, and preparing the data](#Step-2:-Cleaning,-transforming,-and-preparing-the-data)\n",
    "3. [Create and train our model](#Step-3:-Create-and-train-our-model)\n",
    "4. [Viewing the results](#Step-4:-Viewing-the-results)\n",
    "5. [Visualize using QuickSight](https://docs.aws.amazon.com/quicksight/latest/user/create-a-data-set-s3.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's go ahead and import all the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker.amazon.common as smac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading the data from Amazon S3\n",
    "Next, lets get the UFO sightings data that is stored in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "bucket = '<INSERT_BUCKET_NAME_HERE>'\n",
    "prefix = 'ufo_dataset'\n",
    "data_key = 'ufo_fullset.csv'\n",
    "data_location = 's3://{}/{}/{}'.format(bucket, prefix, data_key)\n",
    "\n",
    "df = pd.read_csv(data_location, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reportedTimestamp</th>\n",
       "      <th>eventDate</th>\n",
       "      <th>eventTime</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>weather</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>sighting</th>\n",
       "      <th>physicalEvidence</th>\n",
       "      <th>contact</th>\n",
       "      <th>researchOutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1982-11-29T10:01:48.297Z</td>\n",
       "      <td>1982-11-28</td>\n",
       "      <td>03:17</td>\n",
       "      <td>oval</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>snow</td>\n",
       "      <td>Muriel</td>\n",
       "      <td>Bartell</td>\n",
       "      <td>28.039167</td>\n",
       "      <td>-81.950000</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-03-05T18:36:08.186Z</td>\n",
       "      <td>2006-03-05</td>\n",
       "      <td>04:56</td>\n",
       "      <td>light</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>partly cloudy</td>\n",
       "      <td>Floy</td>\n",
       "      <td>Heaney</td>\n",
       "      <td>33.660278</td>\n",
       "      <td>-117.998333</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-07-31T23:33:55.223Z</td>\n",
       "      <td>2002-07-26</td>\n",
       "      <td>13:43</td>\n",
       "      <td>oval</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>rain</td>\n",
       "      <td>Evelyn</td>\n",
       "      <td>Champlin</td>\n",
       "      <td>41.325278</td>\n",
       "      <td>-72.193611</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>probable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986-08-31T00:50:08.017Z</td>\n",
       "      <td>1986-08-27</td>\n",
       "      <td>16:12</td>\n",
       "      <td>sphere</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>mostly cloudy</td>\n",
       "      <td>Holden</td>\n",
       "      <td>Ward</td>\n",
       "      <td>38.254167</td>\n",
       "      <td>-85.759444</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-09-26T08:47:39.860Z</td>\n",
       "      <td>2004-09-25</td>\n",
       "      <td>17:21</td>\n",
       "      <td>disk</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>rain</td>\n",
       "      <td>Abigayle</td>\n",
       "      <td>Grady</td>\n",
       "      <td>22.308085</td>\n",
       "      <td>69.600603</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>unexplained</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          reportedTimestamp   eventDate eventTime   shape  duration  \\\n",
       "0  1982-11-29T10:01:48.297Z  1982-11-28     03:17    oval        71   \n",
       "1  2006-03-05T18:36:08.186Z  2006-03-05     04:56   light        75   \n",
       "2  2002-07-31T23:33:55.223Z  2002-07-26     13:43    oval        25   \n",
       "3  1986-08-31T00:50:08.017Z  1986-08-27     16:12  sphere        47   \n",
       "4  2004-09-26T08:47:39.860Z  2004-09-25     17:21    disk        59   \n",
       "\n",
       "   witnesses        weather firstName  lastName   latitude   longitude  \\\n",
       "0          1           snow    Muriel   Bartell  28.039167  -81.950000   \n",
       "1          1  partly cloudy      Floy    Heaney  33.660278 -117.998333   \n",
       "2          1           rain    Evelyn  Champlin  41.325278  -72.193611   \n",
       "3          1  mostly cloudy    Holden      Ward  38.254167  -85.759444   \n",
       "4          1           rain  Abigayle     Grady  22.308085   69.600603   \n",
       "\n",
       "  sighting physicalEvidence contact researchOutcome  \n",
       "0        Y                N       N       explained  \n",
       "1        Y                Y       N       explained  \n",
       "2        Y                Y       Y        probable  \n",
       "3        Y                N       N       explained  \n",
       "4        Y                N       N     unexplained  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Cleaning, transforming, and preparing the data\n",
    "Create another DataFrame with just the latitude and longitude attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo = df[['latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.039167</td>\n",
       "      <td>-81.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.660278</td>\n",
       "      <td>-117.998333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.325278</td>\n",
       "      <td>-72.193611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.254167</td>\n",
       "      <td>-85.759444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.308085</td>\n",
       "      <td>69.600603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude   longitude\n",
       "0  28.039167  -81.950000\n",
       "1  33.660278 -117.998333\n",
       "2  41.325278  -72.193611\n",
       "3  38.254167  -85.759444\n",
       "4  22.308085   69.600603"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18000 entries, 0 to 17999\n",
      "Data columns (total 2 columns):\n",
      "latitude     18000 non-null float64\n",
      "longitude    18000 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 281.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_geo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any missing values? False\n"
     ]
    }
   ],
   "source": [
    "missing_values = df_geo.isnull().values.any()\n",
    "print('Are there any missing values? {}'.format(missing_values))\n",
    "if(missing_values):\n",
    "    df_geo[df_geo.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's go ahead and transform the pandas DataFrame (our dataset) into a numpy.ndarray. When we do this each row is converted to a Record object. According to the documentation, this is what the K-Means algorithm expects as training data. This is what we will use as training data for our model.\n",
    "\n",
    "[See the documentation for input training](https://sagemaker.readthedocs.io/en/stable/kmeans.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  28.039167,  -81.95    ],\n",
       "       [  33.66028 , -117.99834 ],\n",
       "       [  41.32528 ,  -72.19361 ],\n",
       "       ...,\n",
       "       [  37.49472 , -120.84556 ],\n",
       "       [  40.771946,  -73.93056 ],\n",
       "       [  64.837776, -147.71638 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = df_geo.values.astype('float32')\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create and train our model\n",
    "In this step we will import and use the built-in SageMaker K-Means algorithm. We will set the number of cluster to 10 (for our 10 sensors), specify the instance type we want to train on, and the location of where we want our model artifact to live. \n",
    "\n",
    "[See the documentation of hyperparameters here](https://docs.aws.amazon.com/sagemaker/latest/dg/k-means-api-config.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import KMeans\n",
    "\n",
    "num_clusters = 10\n",
    "output_location = 's3://' + bucket + '/model-artifacts'\n",
    "\n",
    "kmeans = KMeans(role=role,\n",
    "               instance_count=1,\n",
    "               instance_type='ml.c4.xlarge',\n",
    "               output_path=output_location,\n",
    "               k=num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the job name kmeans-geo-job-20190517133512\n"
     ]
    }
   ],
   "source": [
    "job_name = 'kmeans-geo-job-{}'.format(datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "print('Here is the job name {}'.format(job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-17 13:37:19 Starting - Starting the training job...\n",
      "2019-05-17 13:37:21 Starting - Launching requested ML instances......\n",
      "2019-05-17 13:38:26 Starting - Preparing the instances for training......\n",
      "2019-05-17 13:39:44 Downloading - Downloading input data..\n",
      "\n",
      "2019-05-17 13:40:12 Training - Training image download completed. Training in progress.\n",
      "2019-05-17 13:40:12 Uploading - Uploading generated training model\n",
      "2019-05-17 13:40:12 Completed - Training job completed\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'2', u'k': u'10', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'2', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'10', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 WARNING 140619722299200] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] Using default worker.\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] Create Store: local\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] nvidia-smi took: 0.0252430438995 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'2', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'10', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] number of center slices 1\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1558100402.361402, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1558100402.361373}\n",
      "\u001b[0m\n",
      "\u001b[31m[2019-05-17 13:40:02.361] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 45, \"num_examples\": 1, \"num_bytes\": 160000}\u001b[0m\n",
      "\u001b[31m[2019-05-17 13:40:02.442] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 80, \"num_examples\": 4, \"num_bytes\": 576000}\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] processed a total of 18000 examples\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 18000, \"sum\": 18000.0, \"min\": 18000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}, \"Total Records Seen\": {\"count\": 1, \"max\": 23000, \"sum\": 23000.0, \"min\": 23000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 18000, \"sum\": 18000.0, \"min\": 18000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1558100402.443082, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1558100402.361611}\n",
      "\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] #throughput_metric: host=algo-1, train throughput=220579.989949 records/second\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 WARNING 140619722299200] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] shrinking 100 centers into 10\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] local kmeans attempt #0. Current mean square distance 27.843344\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] local kmeans attempt #1. Current mean square distance 28.573576\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] local kmeans attempt #2. Current mean square distance 25.915253\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] local kmeans attempt #3. Current mean square distance 26.098783\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] local kmeans attempt #4. Current mean square distance 27.912024\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] local kmeans attempt #5. Current mean square distance 25.231770\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] local kmeans attempt #6. Current mean square distance 26.845171\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] local kmeans attempt #7. Current mean square distance 27.047560\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] local kmeans attempt #8. Current mean square distance 28.046276\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] local kmeans attempt #9. Current mean square distance 25.349459\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] finished shrinking process. Mean Square Distance = 25\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] #quality_metric: host=algo-1, train msd <loss>=25.2317695618\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] compute all data-center distances: inner product took: 24.4517%, (0.021202 secs)\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] predict compute msd took: 18.1709%, (0.015756 secs)\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] gradient: cluster size  took: 9.9631%, (0.008639 secs)\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] gradient: cluster center took: 8.7569%, (0.007593 secs)\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] collect from kv store took: 8.4902%, (0.007362 secs)\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] splitting centers key-value pair took: 8.0024%, (0.006939 secs)\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] batch data loading with context took: 7.8072%, (0.006770 secs)\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] compute all data-center distances: point norm took: 6.0801%, (0.005272 secs)\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] gradient: one_hot took: 5.3672%, (0.004654 secs)\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] update state and report convergance took: 1.9272%, (0.001671 secs)\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] compute all data-center distances: center norm took: 0.6530%, (0.000566 secs)\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] update set-up time took: 0.2343%, (0.000203 secs)\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] predict minus dist took: 0.0960%, (0.000083 secs)\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] TOTAL took: 0.0867109298706\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 349.2088317871094, \"sum\": 349.2088317871094, \"min\": 349.2088317871094}, \"initialize.time\": {\"count\": 1, \"max\": 38.21587562561035, \"sum\": 38.21587562561035, \"min\": 38.21587562561035}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.14901161193847656, \"sum\": 0.14901161193847656, \"min\": 0.14901161193847656}, \"update.time\": {\"count\": 1, \"max\": 81.25615119934082, \"sum\": 81.25615119934082, \"min\": 81.25615119934082}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 2.516031265258789, \"sum\": 2.516031265258789, \"min\": 2.516031265258789}, \"_shrink.time\": {\"count\": 1, \"max\": 347.4760055541992, \"sum\": 347.4760055541992, \"min\": 347.4760055541992}}, \"EndTime\": 1558100402.795428, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1558100402.316022}\n",
      "\u001b[0m\n",
      "\u001b[31m[05/17/2019 13:40:02 INFO 140619722299200] Test data is not provided.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 547.003984451294, \"sum\": 547.003984451294, \"min\": 547.003984451294}, \"setuptime\": {\"count\": 1, \"max\": 15.492916107177734, \"sum\": 15.492916107177734, \"min\": 15.492916107177734}}, \"EndTime\": 1558100402.795768, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1558100402.795523}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Billable seconds: 28\n",
      "CPU times: user 695 ms, sys: 6.68 ms, total: 702 ms\n",
      "Wall time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmeans.fit(kmeans.record_set(data_train), job_name=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Viewing the results\n",
    "In this step we will take a look at the model artifact SageMaker created for us and stored onto S3. We have to do a few special things to see the latitude and longitude for our 10 clusters (and the center points of those clusters)\n",
    "\n",
    "[See the documentation of deserilization here](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html#td-deserialization)\n",
    "\n",
    "At this point we need to \"deserilize\" the model artifact. Here we are going to open and review them in our notebook instance. We can unzip the model artifact which will contain model_algo-1. This is just a serialized Apache MXNet object. From here we can load that serialized object into a numpy.ndarray and then extract the clustered centroids from the numpy.ndarray.\n",
    "\n",
    "After we extract the results into a DataFrame of latitudes and longitudes, we can create a CSV with that data, load it onto S3 and then visualize it with QuickSight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "model_key = 'model-artifacts/' + job_name + '/output/model.tar.gz'\n",
    "\n",
    "boto3.resource('s3').Bucket(bucket).download_file(model_key, 'model.tar.gz')\n",
    "os.system('tar -zxvf model.tar.gz')\n",
    "os.system('unzip model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/f4/bc147a1ba7175f9890523ff8f1a928a43ac8a79d5897a067158cac4d092f/mxnet-1.4.1-py2.py3-none-manylinux1_x86_64.whl (28.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 28.4MB 1.6MB/s eta 0:00:01  0% |▎                               | 235kB 35.0MB/s eta 0:00:01    68% |██████████████████████          | 19.6MB 45.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy<1.15.0,>=1.8.2 (from mxnet)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/c4/395ebb218053ba44d64935b3729bc88241ec279915e72100c5979db10945/numpy-1.14.6-cp36-cp36m-manylinux1_x86_64.whl (13.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.8MB 5.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet) (2.20.1)\n",
      "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet)\n",
      "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.20.0->mxnet) (1.23)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.20.0->mxnet) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.20.0->mxnet) (2019.3.9)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.20.0->mxnet) (3.0.4)\n",
      "Installing collected packages: numpy, graphviz, mxnet\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\n",
      "      Successfully uninstalled numpy-1.15.4\n",
      "Successfully installed graphviz-0.8.4 mxnet-1.4.1 numpy-1.14.6\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "Kmeans_model_params = mx.ndarray.load('model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.286369</td>\n",
       "      <td>-74.856453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.558636</td>\n",
       "      <td>115.825752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.375927</td>\n",
       "      <td>-117.235794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.477852</td>\n",
       "      <td>3.664200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.134438</td>\n",
       "      <td>-97.897385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26.707329</td>\n",
       "      <td>-81.378113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46.405426</td>\n",
       "      <td>-120.561981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25.992533</td>\n",
       "      <td>-146.748108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38.832069</td>\n",
       "      <td>-85.299072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>61.760826</td>\n",
       "      <td>-148.924332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude   longitude\n",
       "0  41.286369  -74.856453\n",
       "1  -3.558636  115.825752\n",
       "2  35.375927 -117.235794\n",
       "3  48.477852    3.664200\n",
       "4  36.134438  -97.897385\n",
       "5  26.707329  -81.378113\n",
       "6  46.405426 -120.561981\n",
       "7  25.992533 -146.748108\n",
       "8  38.832069  -85.299072\n",
       "9  61.760826 -148.924332"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_centroids_kmeans = pd.DataFrame(Kmeans_model_params[0].asnumpy())\n",
    "cluster_centroids_kmeans.columns=df_geo.columns\n",
    "cluster_centroids_kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and upload this dataset onto S3 and view within QuickSight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '5B2C5F338C4D94A2',\n",
       "  'HostId': 'EBaTdqW46uapRaIWfzr0UMENSLV4vuhXsUML53S9b4QC4MP0heG2FEcRYKJqYeSum2J8ikhHdrY=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'EBaTdqW46uapRaIWfzr0UMENSLV4vuhXsUML53S9b4QC4MP0heG2FEcRYKJqYeSum2J8ikhHdrY=',\n",
       "   'x-amz-request-id': '5B2C5F338C4D94A2',\n",
       "   'date': 'Fri, 17 May 2019 13:53:38 GMT',\n",
       "   'etag': '\"51e129efa7a05a163e90bd3fd0433c70\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"51e129efa7a05a163e90bd3fd0433c70\"'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "cluster_centroids_kmeans.to_csv(csv_buffer, index=False)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(bucket, 'results/ten_locations_kmeans.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
